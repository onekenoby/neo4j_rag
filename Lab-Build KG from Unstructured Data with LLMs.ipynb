{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pprBYIm-rXFo",
        "outputId": "d7b5ffc8-48de-4a45-cab9-8ee49b57b0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.25.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.8.30)\n",
            "Downloading neo4j-5.25.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=ea8ad489e7d5bb03ff0826b1e8b525d5da3dc296b46217a4998330d0b4a36150\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: neo4j, wikipedia-api\n",
            "Successfully installed neo4j-5.25.0 wikipedia-api-0.7.1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install libraries\n",
        "!pip install wikipedia-api neo4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr4FgbQorsLM",
        "outputId": "3ae2299f-0d49-4ac4-cc61-eb262b835e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import libraries\n",
        "import wikipediaapi\n",
        "import openai\n",
        "from neo4j import GraphDatabase\n",
        "import re"
      ],
      "metadata": {
        "id": "n7yvk3QdrwQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set OpenAI API Key for GPT-based LLM\n",
        "openai.api_key = 'sk-r7L1feU_nIMoF8sLmKCUqKlE9X3PLShebgyJUUaI1BT3BlbkFJCWoi7KHB_oiwLcQor1F6QipfdM_RWEB6gjCHW1cRkA'"
      ],
      "metadata": {
        "id": "SJ85tQCDr2t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract entities from text using OpenAI GPT LLM\n",
        "def extract_entities(text):\n",
        "    prompt = f\"Extract entities and their types from the following text:\\n\\n{text}\\n\\nFormat: Entity - Type (e.g., John Doe - Person)\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "APR-882QsDOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Connect to Neo4j Sandbox Cloud\n",
        "uri = \"bolt://44.204.200.141:7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"raincoats-wheel-assemblies\"\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))"
      ],
      "metadata": {
        "id": "j02wfFIosij4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create nodes in Neo4j\n",
        "def create_node(tx, label, name):\n",
        "    query = f\"MERGE (n:{label} {{name: $name}})\"\n",
        "    tx.run(query, name=name)"
      ],
      "metadata": {
        "id": "m8MbpP71srsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create relationships in Neo4j\n",
        "def create_relationship(tx, entity1, entity2, relationship):\n",
        "    query = (\n",
        "        f\"MATCH (a {{name: $entity1}}), (b {{name: $entity2}}) \"\n",
        "        f\"MERGE (a)-[r:{relationship}]->(b) \"\n",
        "        \"RETURN type(r)\"\n",
        "    )\n",
        "    tx.run(query, entity1=entity1, entity2=entity2)"
      ],
      "metadata": {
        "id": "oqVoTNuDswLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "\n",
        "# Step 5: Fetch Wikipedia page data\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    language='en',\n",
        "    user_agent='my_bot (abc@example.com)'\n",
        ")\n",
        "page_title = \"Artificial_intelligence\"\n",
        "page = wiki.page(page_title)\n",
        "\n",
        "if page.exists():\n",
        "    wiki_text = page.text\n",
        "    print(f\"Text from {page_title}: \\n\", wiki_text[:1000])  # Preview first 1000 characters\n",
        "else:\n",
        "    print(f\"The page '{page_title}' does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtaIAPV9s03_",
        "outputId": "356ed725-1caa-43dd-ed53-55c713e9cfbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.8.30)\n",
            "Text from Artificial_intelligence: \n",
            " Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "Some high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Extract entities from Wikipedia text\n",
        "entities_text = extract_entities(wiki_text[:2000])  # Process portion of the text for demo\n",
        "print(\"Extracted Entities:\\n\", entities_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpHYqIgbthd9",
        "outputId": "5e010c87-defb-4934-f0a7-dc3d4f8e5f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Entities:\n",
            " 1. Artificial intelligence - Concept\n",
            "2. AI - Concept\n",
            "3. machines - Concept\n",
            "4. computer systems - Concept\n",
            "5. computer science - Field\n",
            "6. Google Search - Application\n",
            "7. YouTube - Application\n",
            "8. Amazon - Application\n",
            "9. Netflix - Application\n",
            "10. Google Assistant - Application\n",
            "11. Siri - Application\n",
            "12. Alexa - Application\n",
            "13. Waymo - Application\n",
            "14. ChatGPT - Application\n",
            "15. AI art - Application\n",
            "16. chess - Game\n",
            "17. Go - Game\n",
            "18. reasoning - Goal\n",
            "19. knowledge representation - Goal\n",
            "20. planning - Goal\n",
            "21. learning - Goal\n",
            "22. natural language processing - Goal\n",
            "23. perception - Goal\n",
            "24. support for robotics - Goal\n",
            "25. General intelligence - Concept\n",
            "26. artificial neural networks - Technique\n",
            "27. statistics - Field\n",
            "28. operations research - Field\n",
            "29. economics - Field\n",
            "30. psychology - Field\n",
            "31. linguistics - Field\n",
            "32. philosophy - Field\n",
            "33. neuroscience - Field\n",
            "34. 1956 - Year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Parse and create relationships\n",
        "import re\n",
        "\n",
        "# Function to remove leading numbers, periods, and spaces\n",
        "def clean_entity_name(entity_name):\n",
        "    return re.sub(r\"^\\d+\\.\\s*\", \"\", entity_name).strip()\n",
        "\n",
        "def parse_entities(entities_text):\n",
        "    entity_pattern = r\"(.+) - (.+)\"\n",
        "    entities = []\n",
        "    for line in entities_text.split('\\n'):\n",
        "        match = re.match(entity_pattern, line)\n",
        "        if match:\n",
        "            entity_name, entity_type = match.groups()\n",
        "            entity_name = clean_entity_name(entity_name)\n",
        "            entities.append((entity_name, entity_type.strip()))\n",
        "    return entities\n",
        "\n",
        "entities = parse_entities(entities_text)"
      ],
      "metadata": {
        "id": "rMUiJFoxt8As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCcaotMiuFsv",
        "outputId": "a62f6ca6-bca0-4144-b1b4-1e1d52bfa367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial intelligence', 'Concept'),\n",
              " ('AI', 'Concept'),\n",
              " ('machines', 'Concept'),\n",
              " ('computer systems', 'Concept'),\n",
              " ('computer science', 'Field'),\n",
              " ('Google Search', 'Application'),\n",
              " ('YouTube', 'Application'),\n",
              " ('Amazon', 'Application'),\n",
              " ('Netflix', 'Application'),\n",
              " ('Google Assistant', 'Application'),\n",
              " ('Siri', 'Application'),\n",
              " ('Alexa', 'Application'),\n",
              " ('Waymo', 'Application'),\n",
              " ('ChatGPT', 'Application'),\n",
              " ('AI art', 'Application'),\n",
              " ('chess', 'Game'),\n",
              " ('Go', 'Game'),\n",
              " ('reasoning', 'Goal'),\n",
              " ('knowledge representation', 'Goal'),\n",
              " ('planning', 'Goal'),\n",
              " ('learning', 'Goal'),\n",
              " ('natural language processing', 'Goal'),\n",
              " ('perception', 'Goal'),\n",
              " ('support for robotics', 'Goal'),\n",
              " ('General intelligence', 'Concept'),\n",
              " ('artificial neural networks', 'Technique'),\n",
              " ('statistics', 'Field'),\n",
              " ('operations research', 'Field'),\n",
              " ('economics', 'Field'),\n",
              " ('psychology', 'Field'),\n",
              " ('linguistics', 'Field'),\n",
              " ('philosophy', 'Field'),\n",
              " ('neuroscience', 'Field'),\n",
              " ('1956', 'Year')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create nodes and relationships in Neo4j\n",
        "with driver.session() as session:\n",
        "    for i, (entity1_name, entity1_type) in enumerate(entities):\n",
        "        # Create nodes for the first entity\n",
        "        session.write_transaction(create_node, entity1_type, entity1_name)\n",
        "\n",
        "        for j, (entity2_name, entity2_type) in enumerate(entities):\n",
        "            if i != j:\n",
        "                # Define relationships based on entity types\n",
        "                if entity1_type == \"Application\" and entity2_type == \"Concept\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"USES\")\n",
        "                elif entity1_type == \"Application\" and entity2_type == \"Goal\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"ACHIEVES\")\n",
        "                elif entity1_type == \"Application\" and entity2_type == \"Technique\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"IMPLEMENTED_WITH\")\n",
        "                elif entity1_type == \"Game\" and entity2_type == \"Concept\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"BASED_ON\")\n",
        "                elif entity1_type == \"Field\" and entity2_type == \"Concept\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"STUDIES\")\n",
        "                elif entity1_type == \"Field\" and entity2_type == \"Goal\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"SUPPORTS\")\n",
        "                elif entity1_type == \"Concept\" and entity2_type == \"Field\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"APPLIES_TO\")\n",
        "                elif entity1_type == \"Year\" and entity2_type == \"Concept\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"INTRODUCED_IN\")\n",
        "                elif entity1_type == \"Goal\" and entity2_type == \"Technique\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"ACHIEVED_BY\")\n",
        "                elif entity1_type == \"Concept\" and entity2_type == \"Technique\":\n",
        "                    session.write_transaction(create_relationship, entity1_name, entity2_name, \"ENABLED_BY\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHtUEiLUuq0Z",
        "outputId": "10349a7a-7093-4e5b-f2d7-2bb2018e5f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-39c5d64e944f>:5: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_node, entity1_type, entity1_name)\n",
            "<ipython-input-14-39c5d64e944f>:23: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"APPLIES_TO\")\n",
            "<ipython-input-14-39c5d64e944f>:29: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"ENABLED_BY\")\n",
            "<ipython-input-14-39c5d64e944f>:19: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"STUDIES\")\n",
            "<ipython-input-14-39c5d64e944f>:21: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"SUPPORTS\")\n",
            "<ipython-input-14-39c5d64e944f>:11: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"USES\")\n",
            "<ipython-input-14-39c5d64e944f>:13: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"ACHIEVES\")\n",
            "<ipython-input-14-39c5d64e944f>:15: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"IMPLEMENTED_WITH\")\n",
            "<ipython-input-14-39c5d64e944f>:17: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"BASED_ON\")\n",
            "<ipython-input-14-39c5d64e944f>:27: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"ACHIEVED_BY\")\n",
            "<ipython-input-14-39c5d64e944f>:25: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(create_relationship, entity1_name, entity2_name, \"INTRODUCED_IN\")\n"
          ]
        }
      ]
    }
  ]
}